{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Altering Images so that they meet the requirements from the SHAPR model (GAN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Images are provided by the Swiss Institue of Translational and Entrepreneurial Medicine (SITEM) in Bern, Switzerland.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model requires the images to be in shape of 64x64 pixels. The images in the folder \"Images_for_prediction\" have different shapes according to the size of the red blood cell. \n",
    "\n",
    "This script aims to alter these images and save them as 64x64px images in the folder \"image\" which can then later be used to perform the predictions on them. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to change the size of the image without altering the aspect ratio of the RBC. (Without streching the RBC) \n",
    "### In addition a gray background canvas is added so that it meets the 64x64 pixel size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it on a single image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=72x101>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_image = Image.open(\"Images_for_prediction/cell_frame004148_x0126_y0201_red.jpg\")\n",
    "original_image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate aspect ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_width, desired_height = 64, 64\n",
    "desired_aspect_ratio = desired_width / desired_height"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine the image-scale-factor for resizing while preserving the aspect ratio:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6336633663366337"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_width, current_height = original_image.size\n",
    "current_aspect_ratio = current_width / current_height\n",
    "\n",
    "if current_aspect_ratio > desired_aspect_ratio:\n",
    "    # The original image is wider than the desired aspect ratio, so the width will be the limiting factor.\n",
    "    scale_factor = desired_width / current_width\n",
    "else:\n",
    "    # The original image is taller than the desired aspect ratio, so the height will be the limiting factor.\n",
    "    scale_factor = desired_height / current_height\n",
    "\n",
    "scale_factor "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the new size based on the scale factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_size = (int(current_width * scale_factor), int(current_height * scale_factor))\n",
    "new_size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resize the image while preserving the aspect ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Domin\\AppData\\Local\\Temp\\ipykernel_27424\\3999035377.py:1: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  resized_image = original_image.resize(new_size, Image.ANTIALIAS)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAC0AAABACAAAAACrG6HCAAAEU0lEQVR4nFWWS5LlRgwDEyh2z/1v4Gt6ngh4UWqPrQht9CsSBFKlvwQtRK5ViVo0atsolXpcVagjBTWyK+FBpUhKwD4tSWugHlJx5kOR8C+eulB1t62E2FJATNf0eIWMvu0whVI5IRWAnByYSmhXko2/dMaGSnt4sipbpUdFjJBwJOt4xvyqCnSCHmitR0QWHQnoMeZ8jSXdtWkrzW42JtSUQYB8kGfOQUagQnnSZ1ebqhbqVJUBzTk+RxLmylhSiShoA9XQYknzrXh8gIMEIUpsseOHLdXs0Uhn1PnGB8qDz8GdPClrojwtdMD0zGl1IiQoFpXko1hXMLdkRPE5xjASslBNJXCtE13dICOkGR9b+EgWoNoHorMWk2uAapBlnzmoPkxLLXxWveoeJZKbamQfyeELt1MceqQ6RXh0+nfsFmVQkXK+v5CEoFURba+dTr6enUi3HQCBsLGQaDa0pBQ03z4zI00rqwDYlq6lKAqNACrbLq9otGoFZWnOvkNvdFD09UEi7ciiMi2NaspDaSMTzVHKcU5Ih5ZzDnrLQQUB5j1EPFlkjSnH6Lgqam/D6BZP6xaf33LW6LVnr0FeFZFEBbItHwnZQ18BuV4of45rECrrCHymx6otIVcqvC5CqlRddHBWi/W+XAg8i6iPwLL882xryR2gxCYSii0XORI3/IjKSiS5COWp2rbQoKzOyx+uX2TZtm9vso5ElRY2ekt89U65s7pzP/ZdUlIReU2oluIHfOIMORc1tP+mso8sCe5aMiupaxJdMPXSI9VpsluyvF+xZaGR76db+q9XrgNu41JL7gBGJiltarVUBHPNfaPp3Q1tO5XaNMz5I4FFUGuUyk3blLpbtXRR2zQhZFt9vym8+TzHZWj08TNeMA3YatpdOVxjgOyqIymztrtGVg1Ls71YuN68/xRNidQkfg3bXM1QX4y3UFt4Up2bGkVXuht6QbSlKqdULfNGj2C9VVYorZA3ktJLfhhAQo2RAugNUqOza92iQ6Cj/yTrFnGNUMRWCnb6XhqQaGHdF2s/DKT1G4ks6V2fkA372byS6X+J7s/buBeRGyUXruTebC7vmrSkIgPtyuSj6YKdF1h/2mkbCkxEvDr1yYksqBD1u9LdPzSpNC6ikZbTPdtBr6svehrStkk6asF65tlf2605LO8oXznzEjEDrlkW/S6y6xsJ9xWmsNVnW3wRrwbyfHaTByqzPgCJ2GTT5mV9gEDJtikWR5RN3i1T2sBUbVQaGJc4LY+OgrSUZ1OS0MzPrNlqa7JaUDfX3Una7oaiKVQB2JPYpOV87ebiOUmazXWsIR9b0EXPuM861SKUTdRu3n6GS7wLP3eR3PwWqpIupJukiE4k9/03teKxzdLjNtWtPDQqzAG1hwYrbtcqw+b106aJWpVOTdyGWKihTzSLA4Vtli7tQ5n+YEFd5JpkHik/1/NA7/aAuch+NacEtO8esilk7wnwD42LIS1BJpTkAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=45x64>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resized_image = original_image.resize(new_size, Image.ANTIALIAS)\n",
    "resized_image\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a  square canvas with a gray background:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAAAAACPAi4CAAAALUlEQVR4nO3MMQEAAAjDMMC/CKQiYg9H+je9lTXhDwAAAAAAAAAAAAAAAOA9cEhyASBkpnXdAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get color value for the gray background from the first pixel at the top left corner which is always the background value\n",
    "import cv2\n",
    "img = cv2.imread(\"Images_for_prediction/cell_frame004148_x0126_y0201_red.jpg\",2)\n",
    "background_value = img[0][0]\n",
    "background_value = int(background_value)\n",
    "\n",
    "\n",
    "canvas = Image.new(\"L\", (desired_width, desired_height), background_value) \n",
    "canvas\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paste the resized image onto the center of the canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAAAAACPAi4CAAAE6UlEQVR4nHWXYW7kSg6DP7Iq8+5/g73mbixyf5Qz48xzGgjQCNoqFiWSsv7D10fQQuRalahFo7aNUqnLVYXa30/tP88rqJFdCW9UiqQE7NWStAbqtwKkYu1PioT/4aoLVWfaSogpPVhfCnRMl0fI6JcddqFUTkgFICeL9wISmpFk4w+tbUOlWVwZlanSpf6AQEg4krW8t/mnKtAddEFrXSKy6GsBAV3GrI9tSQc0baU9k4kJ9fP5J4kC5IW891rICFQoV3rNaFLVQq8IqsqA9lpeSxLm9LKkElHQ5ND1gqDFkvYvxdsLWEgQosQWs30xpXpDMEtbWlvdv/CCcuG1cHeulDFRrpZnhQcCTNderVaEBMWikrwU67TILfFrG4vXMoYtIQvV58KutaLTKchrG5H29rKFl2QBqr0gWmOxcyb6nQNk2WsvVC92Sy285p49LSWSm/cCspfk8IHbXRy6pDpFeGv1v7Fb9HoFVKSsXx9IOu6gItoCclY+rtmRnoP0h877ZgJhYyHRTGhJKWj/8tp76/UKrXyXtn0fU4pCo3OEbT+V8JeYRKtWUIZmzT3FjRaKPj6RSN/VaFGZlkY15aK0kYn2UspyVshrAVrWWvymSD0K/U2TiHeGMyL/ItGUZbSMWjUBJHlZINozYpWfbXx0Qbd2e0RwtxLpjJ5sy0tCfjz1vMKp8vX9SfYRAZW1BH7Y6qONy6otIVcq3OJBqlQdv2eN5lH7DxjdRxyxXYOol8DyMVLpWKv83gUosYmEYstFjsSxZ0Rl5QvY3wiKUK6qbQsNymjd0cLRhCz7SeLjK5wfLIkqLUyE9YfgpMjkBz+g1bIPVklF5JajWoov8Irf5ZzFwdn+dsResiQ4iGRGUh9teFwh0YmhnhRItZrMlAx3YVsWPzjSAdDSP5ahFh1epfbY6bsfyCSlTa2WimCOGRxb9MyE06R/F6jUpmGvP6RbBLVGqdy0Pe70bw46VUsHtU0TQqbVLx+7O9641jdPeoop+vS1PWAasNW0M3LuSQfZfU9nSdlju2Nk1TA00+Pl9yE5HvfGAZGaxLeam9M41HtNaOHYyrwUSLWqoiriaxc8WR5NqcoqfW6Jf6kRBOGelLNTphXyRFJ6lg1+KiChxkgBvgau0ZqxDgEh39zqmc6PhnBz3raIqRTslL/m6BsCiRbGvXPtKxdpfbtKhrQ/uLIImTCf8xU+txd8NZHvp38v0JOkEyUnlsn5fXMCr0lLqvcNBdqRyad2B+zAt5WQtg3fMTzmQMSjVa+syIIKUd94joaa9F3OLqKRhtVZ041uFzip0pC2TfK65qkF69rX/DOdmsVwD+Ld03BWltc1D1wzDPpfkV0fV3HvVhSm+pxvnXjaehnUQK7PmeSCysyJwkRMMmnzGiy68+OMaqZNsViiTHK/+3wfo7+29Ualge0Sp+XSUpCGck1KEvp463kGyxleppqajAbUyXGDJG1nDpFvCKBn9ZiV2KRlfczkZH2SNJMf5WzIpy3ooGu71zjVIJRJ1E5ubt4KnHDsCUR3kNz8T6hKOpBOkvLDS1ckn+dRKy7bDF3uWa+bQ6B+uMICtYsGK27HKpsJR0aTJmrVdwQ1cRtioYZe0R58LGyaoUN7/fDa1y8vVwe5JtmXlK//54K/co3vwXLWnOp4UEBzv342hcz5+/75P/PiIUR/0wg6AAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paste_position = ((desired_width - new_size[0]) // 2, (desired_height - new_size[1]) // 2)\n",
    "canvas.paste(resized_image, paste_position)\n",
    "canvas\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the resulting image \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas.save(\"Created_Images/resized_RBC.png\")  \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply above code to all the images in the folder \"Images_for_prediction\" and save to \"image\" as Tif file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized image saved: image\\cell_frame004148_x0126_y0201_red.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Domin\\AppData\\Local\\Temp\\ipykernel_27424\\3224825546.py:39: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  resized_image = original_image.resize(new_size, Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Set the path to the folder containing the images\n",
    "folder_path = \"Images_for_prediction\"  \n",
    "result_path = \"image\" \n",
    "\n",
    "# Set the desired dimensions for resizing\n",
    "desired_width, desired_height = 64, 64\n",
    "desired_aspect_ratio = desired_width / desired_height\n",
    "\n",
    "# Loop over all the files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".png\") or filename.endswith(\".jpg\"):\n",
    "        # Load the original image\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        original_image = Image.open(file_path)\n",
    "\n",
    "        # get pixel values of all corners\n",
    "        top_left_color = original_image.getpixel((0, 0))\n",
    "        top_right_color = original_image.getpixel((original_image.width - 1, 0))\n",
    "        bottom_left_color = original_image.getpixel((0, original_image.height - 1))\n",
    "        bottom_right_color = original_image.getpixel((original_image.width - 1, original_image.height - 1))\n",
    "\n",
    "        # Find the lowest pixelvalue of the four corner for the background color of the canvas\n",
    "        background_color = (min(top_left_color, top_right_color, bottom_left_color, bottom_right_color))\n",
    "       \n",
    "        # Perform the resizing and the canvas creation\n",
    "        current_width, current_height = original_image.size\n",
    "        current_aspect_ratio = current_width / current_height\n",
    "\n",
    "        if current_aspect_ratio > desired_aspect_ratio:\n",
    "            scale_factor = desired_width / current_width\n",
    "        else:\n",
    "            scale_factor = desired_height / current_height\n",
    "\n",
    "        new_size = (int(current_width * scale_factor), int(current_height * scale_factor))\n",
    "\n",
    "        resized_image = original_image.resize(new_size, Image.ANTIALIAS)\n",
    "        resized_image = resized_image.convert(\"L\") # grayscale\n",
    "\n",
    "        canvas = Image.new(\"L\", (desired_width, desired_height), background_color) \n",
    "\n",
    "        paste_position = ((desired_width - new_size[0]) // 2, (desired_height - new_size[1]) // 2)\n",
    "        canvas.paste(resized_image, paste_position)\n",
    "       \n",
    "\n",
    "        # Save the resulting image to the new folder\n",
    "        new_file_path = os.path.join(result_path, filename)\n",
    "        canvas.save(new_file_path)\n",
    "\n",
    "        print(f\"Resized image saved: {new_file_path}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Thresholding so that the RBC is well segmented and the images can be saved to the \"mask\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "a= 175#defined as good result after testing on multiple images \n",
    "img = cv.imread('image/cell_frame004148_x0126_y0201_red.jpg', 2) #example image to test the code\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "ret,thresh = cv.threshold(img,a,255,cv.THRESH_BINARY)\n",
    "\n",
    "title = 'BINARY'\n",
    "cv.imwrite(\"Created_Images/thresholded_RBC.png\", thresh)\n",
    "\n",
    "\n",
    "plt.imshow(thresh,'gray',vmin=0,vmax=255)\n",
    "plt.title(title)\n",
    "plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapted code so that it can be applied to all the images in the folder \"image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Set the path to the folder containing the images\n",
    "folder_path = \"image\" \n",
    "result_path = \"mask\"\n",
    "\n",
    "# Set the threshold value\n",
    "threshold_value = 175 #manually identified\n",
    "\n",
    "\n",
    "# Loop over all the files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        # Load the original image\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        img = cv.imread(file_path, 2)\n",
    "        assert img is not None, f\"{file_path} could not be read, check with os.path.exists()\"\n",
    "\n",
    "        # Apply thresholding\n",
    "        ret, thresh = cv.threshold(img, threshold_value, 255, cv.THRESH_BINARY)\n",
    "\n",
    "        # Save the thresholded image to the output folder\n",
    "        output_file_path = os.path.join(result_path, f\"{filename}\")\n",
    "        \n",
    "        cv.imwrite(output_file_path, thresh)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this script and the images in the folder \"image\" and \"mask\" it is now possible to predict the shape of the RBC. For this the notebook \"BTHE_applying_SHAPR\" is created"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
